{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take 2: Adaboost with Weak Classifiers\n",
    "None of that bagging classifier bullshit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import guys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "# from AdaBoostClassifier import AdaBoostClassifier\n",
    "#%run AdaBoostWeak.py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 5587: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13904/267524165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# column names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/column_names.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcolumn_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msparse_dat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/sparse_df.npz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13904/267524165.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# column names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/column_names.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcolumn_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msparse_dat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/sparse_df.npz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\12156\\anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 5587: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# column names\n",
    "with open('data/column_names.txt', 'r') as f:\n",
    "    column_names = [line.strip() for line in f]\n",
    "\n",
    "sparse_dat = sparse.load_npz(\"data/sparse_df.npz\")\n",
    "\n",
    "# Extract labels from the first column\n",
    "labels = sparse_dat[:, 0]\n",
    "\n",
    "# Create a list of column indices to keep\n",
    "to_keep = list(set(range(sparse_dat.shape[1])) - set([0]))\n",
    "\n",
    "# Extract the design matrix\n",
    "X = sparse_dat[:, to_keep]\n",
    "\n",
    "print(f'labels: \\n{labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix: \n",
      "  (17173, 0)\t1\n",
      "  (17240, 0)\t2\n",
      "  (17164, 1)\t1\n",
      "  (17363, 1)\t1\n",
      "  (17448, 1)\t1\n",
      "  (17910, 1)\t1\n",
      "  (17914, 1)\t1\n",
      "  (17933, 1)\t2\n",
      "  (15801, 2)\t1\n",
      "  (15867, 2)\t1\n",
      "  (16217, 2)\t1\n",
      "  (17173, 2)\t3\n",
      "  (17189, 2)\t1\n",
      "  (17386, 2)\t1\n",
      "  (17765, 2)\t4\n",
      "  (17933, 3)\t2\n",
      "  (17325, 4)\t1\n",
      "  (17366, 4)\t1\n",
      "  (16271, 5)\t1\n",
      "  (16837, 5)\t1\n",
      "  (17933, 6)\t2\n",
      "  (17933, 7)\t2\n",
      "  (17173, 8)\t2\n",
      "  (17933, 8)\t1\n",
      "  (15801, 9)\t1\n",
      "  :\t:\n",
      "  (8386, 56199)\t2\n",
      "  (8669, 56200)\t1\n",
      "  (10316, 56200)\t1\n",
      "  (8805, 56201)\t1\n",
      "  (9218, 56201)\t1\n",
      "  (9565, 56202)\t1\n",
      "  (9814, 56202)\t1\n",
      "  (6232, 56203)\t1\n",
      "  (9353, 56203)\t1\n",
      "  (5661, 56204)\t9\n",
      "  (6860, 56204)\t1\n",
      "  (8698, 56204)\t1\n",
      "  (125, 56205)\t1\n",
      "  (1228, 56205)\t1\n",
      "  (4422, 56205)\t1\n",
      "  (5648, 56206)\t1\n",
      "  (7464, 56206)\t1\n",
      "  (5648, 56207)\t2\n",
      "  (6025, 56208)\t2\n",
      "  (6025, 56209)\t2\n",
      "  (6151, 56210)\t2\n",
      "  (8669, 56211)\t1\n",
      "  (10316, 56211)\t1\n",
      "  (6340, 56212)\t1\n",
      "  (8696, 56212)\t1\n"
     ]
    }
   ],
   "source": [
    "print(f'Design matrix: \\n{X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test split\n",
    "To do: consider stratifying by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14524, 56213)\n",
      "(14524, 1)\n",
      "(3632, 56213)\n",
      "(3632, 1)\n",
      "int64\n",
      "proportion of spam in training data: 0.39568989259157256\n",
      "proportion of spam in testing data: 0.11921806167400881\n"
     ]
    }
   ],
   "source": [
    "# To do - stratify the split \n",
    "n_samples = labels.shape[0]\n",
    "# Use train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.dtype)\n",
    "print(\"proportion of spam in training data:\", (y_train == 1).sum().item() / y_train.shape[0])\n",
    "print(\"proportion of spam in testing data:\", (y_test == 1).sum().item() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(y, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the proportion of type 2 errors - when the true label is 1 - spam, and the predicted label is 0 - ham\n",
    "\n",
    "        Args:\n",
    "        y: true labels\n",
    "        y_pred: predicted labels\n",
    "        \"\"\"\n",
    "        n = y.shape[0]\n",
    "        type2errors = ((y == 1) & (y_pred == 0)).sum().item()\n",
    "        type1errors = ((y == 0) & (y_pred == 1)).sum().item()\n",
    "        correct = (y_pred == y).sum().item()\n",
    "        return type2errors, type1errors, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test models\n",
    "\n",
    "2 models:\n",
    "1. Without penalty\n",
    "2. With penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run AdaBoostWeak.py\n",
    "\n",
    "aboost1 = AdaBoostWeak(type2penalty = False, rounds = 200, maxDTdepth = 5)\n",
    "aboost1.fit(X = X_train, y = y_train.toarray().ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Test Accuracy:  0.5922356828193832\n",
      "unique predictions - should be 0 and 1: [0 1]\n",
      "type 2 errors: 8 \n",
      " type 1 errors: 1473\n",
      "[1.9311982474293699, 1.1922207924007637, 0.6385318941643855, 0.9564294022214502, 0.816069472339187, 0.6922920016770775, 0.6369655768031284, 0.5580145171983981, 0.53676580386847, 0.4237535232743738, 0.4623203222935166, 0.4723842325214209, 0.4895676529238302, 0.3666700342477265, 0.35037721839934366, 0.5165341888678217, 0.5573056346856897, 0.4064054111284078, 0.34746557733007816, 0.3810543285918116, 0.2819655300587526, 0.3205254061893938, 0.2939073708421175, 0.30012073061184613, 0.364602270904182, 0.4133055679593059, 0.32306578039480827, 0.2772096917590599, 0.2989313921385927, 0.29654207372135993, 0.26341570358993205, 0.27857891332401874, 0.27555848356013546, 0.36463992483772384, 0.29851639244450395, 0.20130117787237253, 0.2509984065035767, 0.24513824181768812, 0.20405140928819254, 0.2110796620117299, 0.20614038627549833, 0.20741264415432778, 0.18315574030081108, 0.4067445879608735, 0.4236320490345265, 0.266367554950173, 0.19357862231169282, 0.2363179423557649, 0.2489315477234735, 0.22912194516166115, 0.17374909650306056, 0.1823512076823171, 0.23460292246564238, 0.2341708241108307, 0.20208162883425773, 0.2215793527014139, 0.20943933816085694, 0.18056583153726907, 0.20078716401460248, 0.1980010688830778, 0.1497150791502919, 0.23539117987312946, 0.22506718226637512, 0.23321361368787216, 0.1851911849877023, 0.24599894039252956, 0.2556780452706368, 0.2446180508917406, 0.22039357989358363, 0.16668009363771147, 0.24493106111722948, 0.21685430648257215, 0.16254004206216227, 0.21549878175533718, 0.20738670067414566, 0.169369747332407, 0.17325581791499564, 0.14768776041086507, 0.15159500585107302, 0.1457254107344001, 0.17513650071870618, 0.18122927069383443, 0.14979449604080947, 0.10647986529375873, 0.18885815065572906, 0.22710921706470236, 0.260306122213899, 0.23264110054786938, 0.177935574041331, 0.11270248841751704, 0.12469667119389434, 0.16439659450344363, 0.15468943283162623, 0.1566452436993116, 0.12041755814293803, 0.12983060350118497, 0.18182112374305157, 0.15888775221158646, 0.1856800680884335, 0.19251174844819582, 0.26345848515168024, 0.27303582178825025, 0.19383283368351156, 0.1495842248983564, 0.23350435085455123, 0.2981760070356793, 0.23101654904237495, 0.18985322392209453, 0.169851152831327, 0.12875409181126238, 0.13603741845817052, 0.14715067782742178, 0.14982754602556606, 0.1552894472209685, 0.16514944224775394, 0.13696836105510943, 0.12013131640866304, 0.09808919759305447, 0.09989480324133887, 0.11538715689755667, 0.12123401298657735, 0.14457029995385715, 0.14286757391039762, 0.1452150136181473, 0.1325493019200712, 0.10766148351516584, 0.21307164695042483, 0.21621665170652452, 0.15915459467155327, 0.16782103795387018, 0.17822806436015937, 0.32659023926589614, 0.16277073175109155, 0.20099663432553394, 0.17545892779189196, 0.1198708237714186, 0.1924557355070188, 0.1776373930141128, 0.11113000717733078, 0.059736861918211634, 0.09461817929118332, 0.1652080457748535, 0.14170472625551433, 0.15454074191927422, 0.2078777999148979, 0.16356062974952448, 0.12467701440901277, 0.1222465604896595, 0.13765382187640543, 0.15456707136867134, 0.17283708776595652, 0.1497987344397745, 0.16103902030341002, 0.15899582221370112, 0.12748068020210443, 0.12199874449599916, 0.07427149796283415, 0.16516107599205673, 0.046975091046122006, 0.07391761470390441, 0.14455507868908551, 0.14414605609361553, 0.10573809621744058, 0.09068994868404977, 0.09321105211251603, 0.13515563748103157, 0.15598948229901294, 0.12371254474204071, 0.12414513446169786, 0.12904481853584368, 0.12089521216433571, 0.12099156732362458, 0.09968897301172966, 0.11574170189201483, 0.12262278622172605, 0.18176877565292351, 0.1790556757059132, 0.13971044073386063, 0.07886580020605838, 0.15865623523863026, 0.09682635987820418, 0.19473852857578822, 0.1729324373887334, 0.13380277732049542, 0.10797904428836493, 0.07862047729296555, 0.13511166088716695, 0.16010300191731203, 0.12948637770313096, 0.08282741367286697, 0.07273672214167344, 0.09473886854993552, 0.1040720732614005, 0.11239708963573498, 0.11740869732755689, 0.1327693444693436, 0.17132888730506532, 0.15656151470313634, 0.11891579037720681, 0.09298005398673297]\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = aboost1.predict(X_test)\n",
    "type2, type1, correct = errors(y_test.toarray().ravel(), predictions)\n",
    "print(\"Model 1 Test Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')\n",
    "print(aboost1.alphas)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (no penalty) Training set Accuracy:  0.9809281189754888\n",
      "unique predictions - should be 0 and 1: [0 1]\n",
      "type 2 errors: 140 \n",
      " type 1 errors: 137\n"
     ]
    }
   ],
   "source": [
    "predictions = aboost1.predict(X_train)\n",
    "type2, type1, correct = errors(y_train.toarray().ravel(), predictions)\n",
    "print(\"Model 1 (no penalty) Training set Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning/Hyperparameter search\n",
    "\n",
    "Sigh. So much overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val scores  [0.82181217 0.98430185 0.91297163 0.86312311]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=9)\n",
    "cvs = cross_val_score(clf, X_train,predictions,cv=4)\n",
    "print(\"cross val scores \",cvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rounds', 'type2penalty', 'maxDTdepth'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #checkity check\n",
    "# from importlib import reload\n",
    "# import AdaBoostWeak\n",
    "# reload(AdaBoostWeak)\n",
    "# from AdaBoostWeak import AdaBoostWeak\n",
    "# a= AdaBoostWeak(rounds=100)\n",
    "# a.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clonity checkity check\n",
    "# from sklearn.base import clone\n",
    "# ada = AdaBoostWeak(rounds=100, type2penalty=False, maxDTdepth=1)  # Replace with actual parameters\n",
    "# ada_clone = clone(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaBoostWeak' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13904/1126483889.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0maboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostWeak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m param_grid = [\n\u001b[0;32m     23\u001b[0m     \u001b[1;33m{\u001b[0m\u001b[1;34m'type2penalty'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rounds'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'maxDTdepth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AdaBoostWeak' is not defined"
     ]
    }
   ],
   "source": [
    "# #not adaboost classifier woops\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# clf = DecisionTreeClassifier()\n",
    "# param_grid = [\n",
    "#     {'type2penalty': [False] ,'rounds': [200, 300, 400, 500], 'maxDTdepth': [5,6,7,8,9,10]},\n",
    "#     {'type2penalty': [True] ,'rounds': [200, 300, 400, 500], 'maxDTdepth': [5,6,7,8,9,10]}\n",
    "#     ]\n",
    "\n",
    "# print(type(y_train))\n",
    "# print(y_train.shape)\n",
    "# y_train_dense = y_train.toarray().ravel()\n",
    "# print(y_train.shape)\n",
    "\n",
    "# grid_search = GridSearchCV(clf, param_grid, cv=4)\n",
    "# grid_search.fit(X_train, y_train_dense)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "aboost = AdaBoostWeak(rounds=100)\n",
    "param_grid = [\n",
    "    {'type2penalty': [False], 'rounds': [200, 300, 400, 500], 'maxDTdepth': [5, 6, 7, 8, 9, 10]},\n",
    "    {'type2penalty': [True], 'rounds': [200, 300, 400, 500], 'maxDTdepth': [5, 6, 7, 8, 9, 10]}\n",
    "]\n",
    "\n",
    "print(type(y_train))\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train_dense = y_train.toarray().ravel()\n",
    "\n",
    "print(y_train_dense.shape)\n",
    "grid_search = GridSearchCV(aboost, param_grid, cv=4)\n",
    "grid_search.fit(X_train, y_train_dense)\n",
    "\n",
    "print(\"best params:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "param_grid = [\n",
    "    {'type2penalty': [False] ,'rounds': [200, 300, 400, 500], 'maxDTdepth': [5,6,7,8,9,10]},\n",
    "    {'type2penalty': [True] ,'rounds': [200, 300, 400, 500], 'maxDTdepth': [5,6,7,8,9,10]}\n",
    "    ]\n",
    "\n",
    "\n",
    "model = AdaBoostWeak(type2penalty=False, maxDTdepth=5,rounds=100)\n",
    "scorer = make_scorer(accuracy_score)\n",
    "grid_search=GridSearchCV(estimator=model, param_grid=param_grid, scoring=scorer, cv=5)\n",
    "grid_search.fit(X_train, y_train.toarray().ravel())\n",
    "\n",
    "print(\"best params:\", grid_search.best_params_)\n",
    "print(\"best cross val score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
