{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import guys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from AdaBoostClassifier import AdaBoostClassifier\n",
    "%run AdaBoostClassifier.py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dat = pd.read_csv('data/cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "315    0\n",
      "316    0\n",
      "317    0\n",
      "318    0\n",
      "319    1\n",
      "Name: Category, Length: 320, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = dat[\"Category\"]\n",
    "dat.drop(['Category', 'cleaned_msg', 'nondupe'], inplace=True, axis = 1)\n",
    "columns = dat.columns\n",
    "dat = dat.to_numpy()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 47994)\n",
      "(256,)\n",
      "(64, 47994)\n",
      "(64,)\n",
      "int64\n",
      "proportion of spam in training data: 0.1484375\n",
      "proportion of spam in testing data: 0.15625\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(labels)\n",
    "# Use train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dat, labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.dtype)\n",
    "print(\"proportion of spam in training data:\", (y_train == 1).sum().item() / len(y_train))\n",
    "print(\"proportion of spam in testing data:\", (y_test == 1).sum().item() / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training + Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(y, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the proportion of type 2 errors - when the true label is 1 - spam, and the predicted label is 0 - ham\n",
    "\n",
    "        Args:\n",
    "        y: true labels\n",
    "        y_pred: predicted labels\n",
    "        \"\"\"\n",
    "        n = len(y)\n",
    "        type2errors = ((y == 1) & (y_pred == 0)).sum().item()\n",
    "        type1errors = ((y == 0) & (y_pred == 1)).sum().item()\n",
    "        correct = (y_pred == y).sum().item()\n",
    "        return type2errors, type1errors, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.953125\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 3 \n",
      " type 1 errors: 0\n",
      "[0.00384693 0.00384693 0.00392464 0.00384693 0.00384693 0.00540473\n",
      " 0.00384693 0.00384693 0.00384693 0.00425151 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00400393 0.00384693 0.00384693\n",
      " 0.00384693 0.00392464 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00400393 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00416733 0.00384693 0.0049892  0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.0043374\n",
      " 0.00384693 0.00384693 0.00609382 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00392464\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00442502\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00392464 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00392464 0.0043374  0.00384693 0.00384693\n",
      " 0.00384693 0.00451441 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00416733 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00408481 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.0043374  0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00469865 0.00400393 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00392464 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00400393 0.00400393\n",
      " 0.00416733 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00451441\n",
      " 0.00384693 0.00384693 0.00384693 0.00392464 0.00384693 0.00384693\n",
      " 0.00384693 0.00416733 0.00384693 0.00384693 0.00442502 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00392464\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00408481 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00562531 0.00384693 0.00384693 0.00384693 0.00384693 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693 0.00392464 0.00384693\n",
      " 0.00384693 0.00384693 0.00384693 0.00384693]\n"
     ]
    }
   ],
   "source": [
    "aboost1 = AdaBoostClassifier(n_estimators = 50, lr = 0.01, type2penalty = False, max_DT_depth = None)\n",
    "aboost1.fit(X = X_train, y = y_train)\n",
    "\n",
    "predictions = aboost1.predict(X_test)\n",
    "type2, type1, correct = errors(y_test, predictions)\n",
    "print(\"Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')\n",
    "print(aboost1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.953125\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 3 \n",
      " type 1 errors: 0\n",
      "[0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00451814\n",
      " 0.00385011 0.00385011 0.00385011 0.00408819 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00408819 0.00385011 0.00385011\n",
      " 0.00385011 0.00392789 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00392789 0.00392789\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00434098 0.00385011 0.0054092  0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00408819\n",
      " 0.00385011 0.00385011 0.0051971  0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00392789 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00460942\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00417077 0.00417077 0.00385011 0.00400723 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00392789 0.00530209 0.00385011 0.00385011\n",
      " 0.00385011 0.00417077 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00400723 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00392789 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00434098 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00434098 0.00400723 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00417077\n",
      " 0.00434098 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00451814\n",
      " 0.00385011 0.00385011 0.00385011 0.00392789 0.00385011 0.00385011\n",
      " 0.00385011 0.00442868 0.00385011 0.00385011 0.00460942 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00425503 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00489445 0.00392789 0.00385011 0.00385011 0.00385011 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011 0.00392789 0.00385011\n",
      " 0.00385011 0.00385011 0.00385011 0.00385011]\n"
     ]
    }
   ],
   "source": [
    "aboost2 = AdaBoostClassifier(n_estimators = 50, lr = 0.01, type2penalty = True, max_DT_depth = None)\n",
    "aboost2.fit(X = X_train, y = y_train)\n",
    "predictions = aboost2.predict(X_test)\n",
    "type2, type1, correct = errors(y_test, predictions)\n",
    "print(\"Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')\n",
    "print(aboost2.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (no penalty) Training set Accuracy:  0.96484375\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 0 \n",
      " type 1 errors: 9\n"
     ]
    }
   ],
   "source": [
    "predictions = aboost1.predict(X_train)\n",
    "type2, type1, correct = errors(y_train, predictions)\n",
    "print(\"Model 1 (no penalty) Training set Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 (penalty) Training set Accuracy:  0.96484375\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 0 \n",
      " type 1 errors: 9\n"
     ]
    }
   ],
   "source": [
    "predictions = aboost2.predict(X_train)\n",
    "type2, type1, correct = errors(y_train, predictions)\n",
    "print(\"Model 2 (penalty) Training set Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y = np.ones(3)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=10, lr=0.01)\n",
    "clf.fit(X, y)\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
