{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import guys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "# from AdaBoostClassifier import AdaBoostClassifier\n",
    "%run AdaBoostClassifier.py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "We should leverage the sparse matrix format.\n",
    "\n",
    "https://towardsdatascience.com/working-with-sparse-data-sets-in-pandas-and-sklearn-d26c1cfbe067\n",
    "\n",
    "This shit is incredible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "315    0\n",
      "316    0\n",
      "317    0\n",
      "318    0\n",
      "319    1\n",
      "Name: Category, Length: 320, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "dat = pd.read_csv('data/cleanData.csv')\n",
    "labels = dat[\"Category\"]\n",
    "dat.drop(['Category', 'cleaned_msg', 'nondupe'], inplace=True, axis = 1)\n",
    "columns = dat.columns\n",
    "dat = dat.to_numpy()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "with open('data/column_names.txt', 'r') as f:\n",
    "    column_names = [line.strip() for line in f]\n",
    "\n",
    "sparse_dat = sparse.load_npz(\"data/sparse_df.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: \n",
      "  (2, 0)\t1\n",
      "  (5, 0)\t1\n",
      "  (8, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (11, 0)\t1\n",
      "  (12, 0)\t1\n",
      "  (15, 0)\t1\n",
      "  (19, 0)\t1\n",
      "  (34, 0)\t1\n",
      "  (42, 0)\t1\n",
      "  (54, 0)\t1\n",
      "  (56, 0)\t1\n",
      "  (65, 0)\t1\n",
      "  (67, 0)\t1\n",
      "  (68, 0)\t1\n",
      "  (93, 0)\t1\n",
      "  (95, 0)\t1\n",
      "  (114, 0)\t1\n",
      "  (117, 0)\t1\n",
      "  (120, 0)\t1\n",
      "  (121, 0)\t1\n",
      "  (123, 0)\t1\n",
      "  (134, 0)\t1\n",
      "  (135, 0)\t1\n",
      "  (139, 0)\t1\n",
      "  :\t:\n",
      "  (15952, 0)\t1\n",
      "  (15953, 0)\t1\n",
      "  (15954, 0)\t1\n",
      "  (15955, 0)\t1\n",
      "  (15956, 0)\t1\n",
      "  (15957, 0)\t1\n",
      "  (15958, 0)\t1\n",
      "  (15959, 0)\t1\n",
      "  (15960, 0)\t1\n",
      "  (15961, 0)\t1\n",
      "  (15962, 0)\t1\n",
      "  (15963, 0)\t1\n",
      "  (15964, 0)\t1\n",
      "  (15965, 0)\t1\n",
      "  (15966, 0)\t1\n",
      "  (15967, 0)\t1\n",
      "  (15968, 0)\t1\n",
      "  (15969, 0)\t1\n",
      "  (15970, 0)\t1\n",
      "  (15971, 0)\t1\n",
      "  (15972, 0)\t1\n",
      "  (15973, 0)\t1\n",
      "  (15974, 0)\t1\n",
      "  (15975, 0)\t1\n",
      "  (15976, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "# Extract labels from the first column\n",
    "labels = sparse_dat[:, 0]\n",
    "\n",
    "# Create a list of column indices to keep\n",
    "to_keep = list(set(range(sparse_dat.shape[1])) - set([0]))\n",
    "\n",
    "# Extract the design matrix\n",
    "X = sparse_dat[:, to_keep]\n",
    "\n",
    "print(f'labels: \\n{labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix: \n",
      "  (0, 0)\t1060\n",
      "  (1, 0)\t3125\n",
      "  (2, 0)\t981\n",
      "  (3, 0)\t16024\n",
      "  (4, 0)\t2757\n",
      "  (5, 0)\t992\n",
      "  (6, 0)\t889\n",
      "  (7, 0)\t340\n",
      "  (8, 0)\t16178\n",
      "  (9, 0)\t1218\n",
      "  (10, 0)\t2151\n",
      "  (11, 0)\t3414\n",
      "  (12, 0)\t16079\n",
      "  (13, 0)\t2330\n",
      "  (14, 0)\t1680\n",
      "  (15, 0)\t16520\n",
      "  (16, 0)\t3029\n",
      "  (17, 0)\t866\n",
      "  (18, 0)\t945\n",
      "  (19, 0)\t873\n",
      "  (20, 0)\t2243\n",
      "  (21, 0)\t1800\n",
      "  (22, 0)\t3592\n",
      "  (23, 0)\t123\n",
      "  (24, 0)\t936\n",
      "  :\t:\n",
      "  (8386, 56201)\t2\n",
      "  (8669, 56202)\t1\n",
      "  (10316, 56202)\t1\n",
      "  (8805, 56203)\t1\n",
      "  (9218, 56203)\t1\n",
      "  (9565, 56204)\t1\n",
      "  (9814, 56204)\t1\n",
      "  (6232, 56205)\t1\n",
      "  (9353, 56205)\t1\n",
      "  (5661, 56206)\t9\n",
      "  (6860, 56206)\t1\n",
      "  (8698, 56206)\t1\n",
      "  (125, 56207)\t1\n",
      "  (1228, 56207)\t1\n",
      "  (4422, 56207)\t1\n",
      "  (5648, 56208)\t1\n",
      "  (7464, 56208)\t1\n",
      "  (5648, 56209)\t2\n",
      "  (6025, 56210)\t2\n",
      "  (6025, 56211)\t2\n",
      "  (6151, 56212)\t2\n",
      "  (8669, 56213)\t1\n",
      "  (10316, 56213)\t1\n",
      "  (6340, 56214)\t1\n",
      "  (8696, 56214)\t1\n"
     ]
    }
   ],
   "source": [
    "print(f'Design matrix: \\n{X}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: \n",
    "Why the hell are these numbers so large. Something something is up with the compressed numbers thing.\n",
    "Edit: Nick is a God. Something was up with the dataframe copy. He fixed it. Jonathan likes men."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14524, 56216)\n",
      "(14524, 1)\n",
      "(3632, 56216)\n",
      "(3632, 1)\n",
      "int64\n",
      "proportion of spam in training data: 0.39568989259157256\n",
      "proportion of spam in testing data: 0.11921806167400881\n"
     ]
    }
   ],
   "source": [
    "# To do - stratify the split \n",
    "n_samples = labels.shape[0]\n",
    "# Use train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(sparse_dat, labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.dtype)\n",
    "print(\"proportion of spam in training data:\", (y_train == 1).sum().item() / y_train.shape[0])\n",
    "print(\"proportion of spam in testing data:\", (y_test == 1).sum().item() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training + Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(y, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the proportion of type 2 errors - when the true label is 1 - spam, and the predicted label is 0 - ham\n",
    "\n",
    "        Args:\n",
    "        y: true labels\n",
    "        y_pred: predicted labels\n",
    "        \"\"\"\n",
    "        n = y.shape[0]\n",
    "        type2errors = ((y == 1) & (y_pred == 0)).sum().item()\n",
    "        type1errors = ((y == 0) & (y_pred == 1)).sum().item()\n",
    "        correct = (y_pred == y).sum().item()\n",
    "        return type2errors, type1errors, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 0 \n",
      " type 1 errors: 0\n",
      "[6.8851556e-05 6.8851556e-05 6.8851556e-05 ... 6.8851556e-05 6.8851556e-05\n",
      " 6.8851556e-05]\n"
     ]
    }
   ],
   "source": [
    "aboost1 = AdaBoostClassifier(n_estimators = 50, lr = 0.01, type2penalty = False, max_DT_depth = None)\n",
    "aboost1.fit(X = X_train, y = y_train.toarray().ravel())\n",
    "\n",
    "predictions = aboost1.predict(X_test)\n",
    "type2, type1, correct = errors(y_test.toarray().ravel(), predictions)\n",
    "print(\"Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')\n",
    "print(aboost1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 0 \n",
      " type 1 errors: 0\n",
      "[6.8851556e-05 6.8851556e-05 6.8851556e-05 ... 6.8851556e-05 6.8851556e-05\n",
      " 6.8851556e-05]\n"
     ]
    }
   ],
   "source": [
    "aboost2 = AdaBoostClassifier(n_estimators = 50, lr = 0.01, type2penalty = True, max_DT_depth = None)\n",
    "aboost2.fit(X = X_train, y = y_train.toarray().ravel())\n",
    "\n",
    "predictions = aboost2.predict(X_test)\n",
    "type2, type1, correct = errors(y_test.toarray().ravel(), predictions)\n",
    "print(\"Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')\n",
    "print(aboost2.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 (no penalty) Training set Accuracy:  1.0\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 0 \n",
      " type 1 errors: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = aboost1.predict(X_train)\n",
    "type2, type1, correct = errors(y_train.toarray().ravel(), predictions)\n",
    "print(\"Model 1 (no penalty) Training set Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 (penalty) Training set Accuracy:  1.0\n",
      "unique predictions - should be 0 and 1: [0. 1.]\n",
      "type 2 errors: 0 \n",
      " type 1 errors: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = aboost2.predict(X_train)\n",
    "type2, type1, correct = errors(y_train.toarray().ravel(), predictions)\n",
    "print(\"Model 2 (penalty) Training set Accuracy: \", correct/len(predictions))\n",
    "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
    "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
