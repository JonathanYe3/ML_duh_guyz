{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Take 2\n",
    "The other one is too sus I will try to start with sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_11968\\4071407081.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1['Category'] = df1['Category'].replace({'ham': 0, 'spam': 1})\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_11968\\4071407081.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"data/enronSpamSubset.csv\", usecols=[1,0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16146, 2) (23705, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_11968\\4071407081.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(\"data/lingSpam.csv\", usecols=[1,0])\n"
     ]
    }
   ],
   "source": [
    "# Check location of the data\n",
    "df1 = pd.read_csv(\"data/spam.csv\", usecols=[0,1])\n",
    "df1['Category'] = df1['Category'].replace({'ham': 0, 'spam': 1})\n",
    "\n",
    "df2 = pd.read_csv(\"data/enronSpamSubset.csv\", usecols=[1,0])\n",
    "df3 = pd.read_csv(\"data/lingSpam.csv\", usecols=[1,0])\n",
    "#df4 = pd.read_csv(\"data/completeSpamAssassin.csv\", usecols=[1,0])\n",
    "\n",
    "print(df2.shape, df3.shape)\n",
    "df2.columns = df1.columns\n",
    "df3.columns = df1.columns\n",
    "#df4.columns = df1.columns\n",
    "\n",
    "#Removed SpamAssassin because it looks like ass\n",
    "allData = pd.concat([df1, df2, df3],ignore_index = True)\n",
    "allData = allData[pd.to_numeric(allData['Category'], errors='coerce').notna()]\n",
    "allData = allData.dropna()\n",
    "allData.iloc[:, 0] = allData.iloc[:, 0].astype(int)\n",
    "allData = allData[allData['Category'].isin([0, 1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Count of label:\n",
      " Category\n",
      "0    11976\n",
      "1     6180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(allData['Message'][0])\n",
    "print(\"Count of label:\\n\",allData['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to fix that one spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation, lemmatize, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \n",
       "0      Go until jurong point crazy Available only in ...  \n",
       "1                                Ok lar Joking wif u oni  \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3            U dun say so early hor U c already then say  \n",
       "4      Nah I dont think he goes to usf he lives aroun...  \n",
       "...                                                  ...  \n",
       "30407   the position will be available from late octo...  \n",
       "34810                                        Subject 30   \n",
       "34840   its not the best but will get you started if ...  \n",
       "35892   cleanest list on the internet today  only  69...  \n",
       "40824   the position will be available from late octo...  \n",
       "\n",
       "[18156 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    nonP_text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return nonP_text\n",
    "\n",
    "allData['no_punc'] = allData['Message'].apply(lambda x: remove_punc(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [Go, until, jurong, point, crazy, Available, o...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...  \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...  \n",
       "...                                                  ...  \n",
       "30407  [, the, position, will, be, available, from, l...  \n",
       "34810                                    [Subject, 30, ]  \n",
       "34840  [, its, not, the, best, but, will, get, you, s...  \n",
       "35892  [, cleanest, list, on, the, internet, today, o...  \n",
       "40824  [, the, position, will, be, available, from, l...  \n",
       "\n",
       "[18156 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    return tokens\n",
    "\n",
    "allData['tokenized'] = allData['no_punc'].apply(lambda x: tokenize(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3          [U, dun, say, early, hor, U, c, already, say]  \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...  \n",
       "...                                                  ...  \n",
       "30407  [, position, available, late, october, 1995, e...  \n",
       "34810                                    [Subject, 30, ]  \n",
       "34840  [, best, get, started, dont, one, prices, quot...  \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...  \n",
       "40824  [, position, available, late, october, 1995, e...  \n",
       "\n",
       "[18156 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(token):\n",
    "    text = [word for word in token if word not in stopwords]# to remove all stopwords\n",
    "    return text\n",
    "\n",
    "allData['nonstop'] = allData['tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>Lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[Nah, I, dont, think, go, usf, life, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quote, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, clean, list, internet, today, 69, dollar, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 1995, e...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, best, get, started, dont, one, prices, quot...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, position, available, late, october, 1995, e...   \n",
       "\n",
       "                                                  Lemmas  \n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3          [U, dun, say, early, hor, U, c, already, say]  \n",
       "4      [Nah, I, dont, think, go, usf, life, around, t...  \n",
       "...                                                  ...  \n",
       "30407  [, position, available, late, october, 1995, e...  \n",
       "34810                                    [Subject, 30, ]  \n",
       "34840  [, best, get, start, dont, one, price, quote, ...  \n",
       "35892  [, clean, list, internet, today, 69, dollar, p...  \n",
       "40824  [, position, available, late, october, 1995, e...  \n",
       "\n",
       "[18156 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "\n",
    "# From https://www.ibm.com/topics/stemming-lemmatization \n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return wordnet.NOUN\n",
    "       \n",
    "def lemmatize_email(words):\n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return lemmatized_words\n",
    "\n",
    "#allData['cleaned_msg'] = allData['stemmed'].apply(lambda x: lemmatizer(x))\n",
    "allData['Lemmas'] = allData['nonstop'].apply(lambda x: lemmatize_email(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Free', 'entry', '69', 'wkly', 'comp', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '69', 'Text', 'FA', '69', 'receive', 'entry', 'questionstd', 'txt', 'rateTCs', 'apply', '08452810075over18s']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>CompressedNums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[Free, entry, 69, wkly, comp, win, FA, Cup, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[Nah, I, dont, think, go, usf, life, around, t...</td>\n",
       "      <td>[Nah, I, dont, think, go, usf, life, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, position, available, late, october, 69, ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 69, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quote, ...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quote, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, clean, list, internet, today, 69, dollar, p...</td>\n",
       "      <td>[, clean, list, internet, today, 69, dollar, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, position, available, late, october, 69, ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 1995, e...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, best, get, started, dont, one, prices, quot...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, position, available, late, october, 1995, e...   \n",
       "\n",
       "                                                  Lemmas  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, go, usf, life, around, t...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 1995, e...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, best, get, start, dont, one, price, quote, ...   \n",
       "35892  [, clean, list, internet, today, 69, dollar, p...   \n",
       "40824  [, position, available, late, october, 1995, e...   \n",
       "\n",
       "                                          CompressedNums  \n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, 69, wkly, comp, win, FA, Cup, fi...  \n",
       "3          [U, dun, say, early, hor, U, c, already, say]  \n",
       "4      [Nah, I, dont, think, go, usf, life, around, t...  \n",
       "...                                                  ...  \n",
       "30407  [, position, available, late, october, 69, ear...  \n",
       "34810                                    [Subject, 69, ]  \n",
       "34840  [, best, get, start, dont, one, price, quote, ...  \n",
       "35892  [, clean, list, internet, today, 69, dollar, p...  \n",
       "40824  [, position, available, late, october, 69, ear...  \n",
       "\n",
       "[18156 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compress_numbers(words):\n",
    "    # Use list comprehension for more efficient looping\n",
    "    return ['69' if word.isnumeric() or is_float(word) else word for word in words]\n",
    "\n",
    "def is_float(word):\n",
    "    # Helper function to check if a word can be converted to a float\n",
    "    try:\n",
    "        float(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "## Compressing Numbers\n",
    "print(compress_numbers(allData['Lemmas'][2]))\n",
    "allData['CompressedNums'] = allData['Lemmas'].apply(lambda x: compress_numbers(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep words that show up more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Free', 'entry', '69', 'wkly', 'comp', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '69', 'Text', 'FA', '69', 'receive', 'entry', 'questionstd', 'txt', 'rateTCs', 'apply', '08452810075over18s']\n"
     ]
    }
   ],
   "source": [
    "cleanData = allData[['Category', 'CompressedNums']].copy()\n",
    "#cleanData['CompressedNums'][2]\n",
    "allData['Lemmas'][2]\n",
    "print(compress_numbers(allData['Lemmas'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                     CompressedNums  000yen  00a  \\\n",
      "0        0  Go jurong point crazy Available bugis n great ...       0    0   \n",
      "1        0                            Ok lar Joking wif u oni       0    0   \n",
      "2        1  Free entry 69 wkly comp win FA Cup final tkts ...       0    0   \n",
      "3        0                U dun say early hor U c already say       0    0   \n",
      "4        0         Nah I dont think go usf life around though       0    0   \n",
      "\n",
      "   00am  00coffee  00h  00hfstahlke  00j  00m  ...  útil  über  üll  ýle  \\\n",
      "0     0         0    0            0    0    0  ...     0     0    0    0   \n",
      "1     0         0    0            0    0    0  ...     0     0    0    0   \n",
      "2     0         0    0            0    0    0  ...     0     0    0    0   \n",
      "3     0         0    0            0    0    0  ...     0     0    0    0   \n",
      "4     0         0    0            0    0    0  ...     0     0    0    0   \n",
      "\n",
      "   ýngýlýzce  ýþ  ýþçý  þcómo  þãõ  þù  \n",
      "0          0   0     0      0    0   0  \n",
      "1          0   0     0      0    0   0  \n",
      "2          0   0     0      0    0   0  \n",
      "3          0   0     0      0    0   0  \n",
      "4          0   0     0      0    0   0  \n",
      "\n",
      "[5 rows x 56216 columns]\n",
      "   000yen  00a  00am  00coffee  00h  00hfstahlke  00j  00m  00p  00pm  ...  \\\n",
      "0       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "1       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "2       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "3       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "4       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "\n",
      "   útil  über  üll  ýle  ýngýlýzce  ýþ  ýþçý  þcómo  þãõ  þù  \n",
      "0     0     0    0    0          0   0     0      0    0   0  \n",
      "1     0     0    0    0          0   0     0      0    0   0  \n",
      "2     0     0    0    0          0   0     0      0    0   0  \n",
      "3     0     0    0    0          0   0     0      0    0   0  \n",
      "4     0     0    0    0          0   0     0      0    0   0  \n",
      "\n",
      "[5 rows x 56214 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert 'CompressedNums' to a single string per row\n",
    "cleanData['CompressedNums'] = cleanData['CompressedNums'].apply(' '.join)\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the 'CompressedNums' column\n",
    "X = vectorizer.fit_transform(cleanData['CompressedNums'])\n",
    "\n",
    "# Convert the result to a sparse DataFrame\n",
    "count_df = pd.DataFrame.sparse.from_spmatrix(X, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Find words that appear in multiple emails\n",
    "counts = count_df.sum(axis=0)\n",
    "multiple_appearances = counts[counts >= 2].index\n",
    "\n",
    "# Keep only the columns for words that appear in multiple emails\n",
    "count_df = count_df[multiple_appearances]\n",
    "\n",
    "# Concatenate the sparse DataFrame with the original DataFrame\n",
    "cleanData = cleanData.reset_index(drop=True)\n",
    "count_df = count_df.reset_index(drop=True)\n",
    "cleanData = pd.concat([cleanData, count_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18156, 56216)\n",
      "   000yen  00a  00am  00coffee  00h  00hfstahlke  00j  00m  00p  00pm  ...  \\\n",
      "0       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "1       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "2       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "3       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "4       0    0     0         0    0            0    0    0    0     0  ...   \n",
      "\n",
      "   útil  über  üll  ýle  ýngýlýzce  ýþ  ýþçý  þcómo  þãõ  þù  \n",
      "0     0     0    0    0          0   0     0      0    0   0  \n",
      "1     0     0    0    0          0   0     0      0    0   0  \n",
      "2     0     0    0    0          0   0     0      0    0   0  \n",
      "3     0     0    0    0          0   0     0      0    0   0  \n",
      "4     0     0    0    0          0   0     0      0    0   0  \n",
      "\n",
      "[5 rows x 56214 columns]\n",
      "Index(['000yen', '00a', '00am', '00coffee', '00h', '00hfstahlke', '00j', '00m',\n",
      "       '00p', '00pm',\n",
      "       ...\n",
      "       'útil', 'über', 'üll', 'ýle', 'ýngýlýzce', 'ýþ', 'ýþçý', 'þcómo', 'þãõ',\n",
      "       'þù'],\n",
      "      dtype='object', length=56214)\n",
      "       Category  CompressedNums  000yen  00a  00am  00coffee  00h  \\\n",
      "0             0            1060       0    0     0         0    0   \n",
      "1             0            3125       0    0     0         0    0   \n",
      "2             1             981       0    0     0         0    0   \n",
      "3             0           16024       0    0     0         0    0   \n",
      "4             0            2757       0    0     0         0    0   \n",
      "...         ...             ...     ...  ...   ...       ...  ...   \n",
      "18151         0              22       0    0     0         0    0   \n",
      "18152         0            3746       0    0     0         0    0   \n",
      "18153         0              14       0    0     0         0    0   \n",
      "18154         0              15       0    0     0         0    0   \n",
      "18155         0              22       0    0     0         0    0   \n",
      "\n",
      "       00hfstahlke  00j  00m  ...  útil  über  üll  ýle  ýngýlýzce  ýþ  ýþçý  \\\n",
      "0                0    0    0  ...     0     0    0    0          0   0     0   \n",
      "1                0    0    0  ...     0     0    0    0          0   0     0   \n",
      "2                0    0    0  ...     0     0    0    0          0   0     0   \n",
      "3                0    0    0  ...     0     0    0    0          0   0     0   \n",
      "4                0    0    0  ...     0     0    0    0          0   0     0   \n",
      "...            ...  ...  ...  ...   ...   ...  ...  ...        ...  ..   ...   \n",
      "18151            0    0    0  ...     0     0    0    0          0   0     0   \n",
      "18152            0    0    0  ...     0     0    0    0          0   0     0   \n",
      "18153            0    0    0  ...     0     0    0    0          0   0     0   \n",
      "18154            0    0    0  ...     0     0    0    0          0   0     0   \n",
      "18155            0    0    0  ...     0     0    0    0          0   0     0   \n",
      "\n",
      "       þcómo  þãõ  þù  \n",
      "0          0    0   0  \n",
      "1          0    0   0  \n",
      "2          0    0   0  \n",
      "3          0    0   0  \n",
      "4          0    0   0  \n",
      "...      ...  ...  ..  \n",
      "18151      0    0   0  \n",
      "18152      0    0   0  \n",
      "18153      0    0   0  \n",
      "18154      0    0   0  \n",
      "18155      0    0   0  \n",
      "\n",
      "[18156 rows x 56216 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleanData.shape)\n",
    "print(count_df.head())\n",
    "print(multiple_appearances)\n",
    "print(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "\n",
    "# Convert categorical data to numeric codes\n",
    "for col in cleanData.columns:\n",
    "    if cleanData[col].dtype == 'object':\n",
    "        cleanData[col] = pd.Categorical(cleanData[col]).codes\n",
    "\n",
    "# Convert each column to a sparse array and stack them\n",
    "sparse_matrix = vstack([csr_matrix(cleanData[col].values) for col in cleanData.columns])\n",
    "sparse_matrix = sparse_matrix.transpose()\n",
    "\n",
    "# Keep a separate list of column names\n",
    "column_names = cleanData.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that it works with one email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18156, 56216)\n",
      "56216\n",
      "  (2, 0)\t1\n",
      "  (5, 0)\t1\n",
      "  (8, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (11, 0)\t1\n",
      "  (12, 0)\t1\n",
      "  (15, 0)\t1\n",
      "  (19, 0)\t1\n",
      "  (34, 0)\t1\n",
      "  (42, 0)\t1\n",
      "  (54, 0)\t1\n",
      "  (56, 0)\t1\n",
      "  (65, 0)\t1\n",
      "  (67, 0)\t1\n",
      "  (68, 0)\t1\n",
      "  (93, 0)\t1\n",
      "  (95, 0)\t1\n",
      "  (114, 0)\t1\n",
      "  (117, 0)\t1\n",
      "  (120, 0)\t1\n",
      "  (121, 0)\t1\n",
      "  (123, 0)\t1\n",
      "  (134, 0)\t1\n",
      "  (135, 0)\t1\n",
      "  (139, 0)\t1\n",
      "  :\t:\n",
      "  (8386, 56202)\t2\n",
      "  (8669, 56203)\t1\n",
      "  (10316, 56203)\t1\n",
      "  (8805, 56204)\t1\n",
      "  (9218, 56204)\t1\n",
      "  (9565, 56205)\t1\n",
      "  (9814, 56205)\t1\n",
      "  (6232, 56206)\t1\n",
      "  (9353, 56206)\t1\n",
      "  (5661, 56207)\t9\n",
      "  (6860, 56207)\t1\n",
      "  (8698, 56207)\t1\n",
      "  (125, 56208)\t1\n",
      "  (1228, 56208)\t1\n",
      "  (4422, 56208)\t1\n",
      "  (5648, 56209)\t1\n",
      "  (7464, 56209)\t1\n",
      "  (5648, 56210)\t2\n",
      "  (6025, 56211)\t2\n",
      "  (6025, 56212)\t2\n",
      "  (6151, 56213)\t2\n",
      "  (8669, 56214)\t1\n",
      "  (10316, 56214)\t1\n",
      "  (6340, 56215)\t1\n",
      "  (8696, 56215)\t1\n"
     ]
    }
   ],
   "source": [
    "print(sparse_matrix.shape)\n",
    "print(len(column_names))\n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CompressedNums', 'joking', 'lar', 'ok', 'oni', 'wif']\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of non-zero elements in the first row of the sparse matrix\n",
    "non_zero_indices = sparse_matrix[1].nonzero()[1]\n",
    "\n",
    "# Get the corresponding column names\n",
    "tokens = [column_names[i] for i in non_zero_indices]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"data/sparse_df.npz\", sparse_matrix)\n",
    "# Save column names to a file\n",
    "with open('data/column_names.txt', 'w') as f:\n",
    "    for item in column_names:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
