{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c10462e-288f-487b-b4e3-56d3221ab0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jonat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6c1fb6-81b9-438a-8e1c-6edc6b4447cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_5104\\1491583820.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1['Category'] = df1['Category'].replace({'ham': 0, 'spam': 1})\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_5104\\1491583820.py:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"data/enronSpamSubset.csv\", usecols=[1,0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16146, 2) (23705, 2) (22409, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_5104\\1491583820.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df3 = pd.read_csv(\"data/lingSpam.csv\", usecols=[1,0])\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_5104\\1491583820.py:7: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv(\"data/completeSpamAssassin.csv\", usecols=[1,0])\n"
     ]
    }
   ],
   "source": [
    "# Check location of the data\n",
    "df1 = pd.read_csv(\"data/spam.csv\", usecols=[0,1])\n",
    "df1['Category'] = df1['Category'].replace({'ham': 0, 'spam': 1})\n",
    "\n",
    "df2 = pd.read_csv(\"data/enronSpamSubset.csv\", usecols=[1,0])\n",
    "df3 = pd.read_csv(\"data/lingSpam.csv\", usecols=[1,0])\n",
    "df4 = pd.read_csv(\"data/completeSpamAssassin.csv\", usecols=[1,0])\n",
    "\n",
    "print(df2.shape, df3.shape, df4.shape)\n",
    "df2.columns = df1.columns\n",
    "df3.columns = df1.columns\n",
    "df4.columns = df1.columns\n",
    "\n",
    "#Removed SpamAssassin this looks like ass\n",
    "allData = pd.concat([df1, df2, df3],ignore_index = True)\n",
    "allData = allData[pd.to_numeric(allData['Category'], errors='coerce').notna()]\n",
    "allData = allData.dropna()\n",
    "allData.iloc[:, 0] = allData.iloc[:, 0].astype(int)\n",
    "allData = allData[allData['Category'].isin([0, 1])]\n",
    "\n",
    "\n",
    "#print(df3, df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0f14e2-e71c-4234-9deb-df029c4fe6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(allData['Message'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12da9ccd-8f4c-4062-bfe7-34d59f80009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of label:\n",
      " Category\n",
      "0    11976\n",
      "1     6180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of label:\\n\",allData['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97decfee-b1be-4718-ae37-bd0dee6644f0",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e69fa4e-5598-4571-aa00-ad1ebcf8ba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf2940d-36ff-4f21-9bf1-5cd3495fcdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    nonP_text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return nonP_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80e4e9b-8fd6-44a9-add1-5a04bddcbc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \n",
       "0      Go until jurong point crazy Available only in ...  \n",
       "1                                Ok lar Joking wif u oni  \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3            U dun say so early hor U c already then say  \n",
       "4      Nah I dont think he goes to usf he lives aroun...  \n",
       "...                                                  ...  \n",
       "30407   the position will be available from late octo...  \n",
       "34810                                        Subject 30   \n",
       "34840   its not the best but will get you started if ...  \n",
       "35892   cleanest list on the internet today  only  69...  \n",
       "40824   the position will be available from late octo...  \n",
       "\n",
       "[18156 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData['no_punc'] = allData['Message'].apply(lambda x: remove_punc(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "180a3d2e-b697-4217-96d5-52ef80ffbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68da4a0-a4c0-4037-b10c-8a6280cba296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13a6ae7-77ca-456c-a4e5-8e097729fdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [Go, until, jurong, point, crazy, Available, o...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...  \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...  \n",
       "...                                                  ...  \n",
       "30407  [, the, position, will, be, available, from, l...  \n",
       "34810                                    [Subject, 30, ]  \n",
       "34840  [, its, not, the, best, but, will, get, you, s...  \n",
       "35892  [, cleanest, list, on, the, internet, today, o...  \n",
       "40824  [, the, position, will, be, available, from, l...  \n",
       "\n",
       "[18156 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData['tokenized'] = allData['no_punc'].apply(lambda x: tokenize(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3304be-f739-4dcd-affe-d004ca539a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a51a9063-45d8-45b7-81eb-2461e870dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(token):\n",
    "    text = [word for word in token if word not in stopwords]# to remove all stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff39a8ab-5edc-4203-b0c3-c681bbd7d63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3          [U, dun, say, early, hor, U, c, already, say]  \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...  \n",
       "...                                                  ...  \n",
       "30407  [, position, available, late, october, 1995, e...  \n",
       "34810                                    [Subject, 30, ]  \n",
       "34840  [, best, get, started, dont, one, prices, quot...  \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...  \n",
       "40824  [, position, available, late, october, 1995, e...  \n",
       "\n",
       "[18156 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData['nonstop'] = allData['tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312809a5-57a7-4e78-87ac-9783092d3fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, posit, avail, late, octob, 1995, earli, feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quot, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, posit, avail, late, octob, 1995, earli, feb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 1995, e...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, best, get, started, dont, one, prices, quot...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, position, available, late, october, 1995, e...   \n",
       "\n",
       "                                                 stemmed  \n",
       "0      [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                           [ok, lar, joke, wif, u, oni]  \n",
       "2      [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3          [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4      [nah, i, dont, think, goe, usf, live, around, ...  \n",
       "...                                                  ...  \n",
       "30407  [, posit, avail, late, octob, 1995, earli, feb...  \n",
       "34810                                    [subject, 30, ]  \n",
       "34840  [, best, get, start, dont, one, price, quot, u...  \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...  \n",
       "40824  [, posit, avail, late, octob, 1995, earli, feb...  \n",
       "\n",
       "[18156 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.SnowballStemmer(\"english\",ignore_stopwords = True)\n",
    "\n",
    "def stemming(t_text):\n",
    "    text = [ps.stem(word) for word in t_text]\n",
    "    return text\n",
    "\n",
    "allData['stemmed'] = allData['nonstop'].apply(lambda x: stemming(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a0a577-a350-4d05-971c-0b6248362729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "\n",
    "# From https://www.ibm.com/topics/stemming-lemmatization \n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return wordnet.NOUN\n",
    "       \n",
    "def lemmatize_email(words):\n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_numbers(words):\n",
    "    # for word in words:\n",
    "    #     try: \n",
    "    #         word = float(word)\n",
    "    #         word = 69\n",
    "    #     except: continue\n",
    "    # return words\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        try: \n",
    "            float(word)\n",
    "            words[counter] = '69'\n",
    "            counter+=1\n",
    "            continue\n",
    "        except: pass\n",
    "        if word.isnumeric():\n",
    "            words[counter] = '69'\n",
    "        else:\n",
    "            pass\n",
    "        counter+=1\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f82caff-5a93-4cab-91ad-b7c9afff3e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>Lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
       "      <td>[Nah, I, dont, think, go, usf, life, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, posit, avail, late, octob, 1995, earli, feb...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quot, u...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quote, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, clean, list, internet, today, 69, dollar, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, posit, avail, late, octob, 1995, earli, feb...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 1995, e...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, best, get, started, dont, one, prices, quot...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, position, available, late, october, 1995, e...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "0      [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                           [ok, lar, joke, wif, u, oni]   \n",
       "2      [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3          [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4      [nah, i, dont, think, goe, usf, live, around, ...   \n",
       "...                                                  ...   \n",
       "30407  [, posit, avail, late, octob, 1995, earli, feb...   \n",
       "34810                                    [subject, 30, ]   \n",
       "34840  [, best, get, start, dont, one, price, quot, u...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, posit, avail, late, octob, 1995, earli, feb...   \n",
       "\n",
       "                                                  Lemmas  \n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3          [U, dun, say, early, hor, U, c, already, say]  \n",
       "4      [Nah, I, dont, think, go, usf, life, around, t...  \n",
       "...                                                  ...  \n",
       "30407  [, position, available, late, october, 1995, e...  \n",
       "34810                                    [Subject, 30, ]  \n",
       "34840  [, best, get, start, dont, one, price, quote, ...  \n",
       "35892  [, clean, list, internet, today, 69, dollar, p...  \n",
       "40824  [, position, available, late, october, 1995, e...  \n",
       "\n",
       "[18156 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allData['cleaned_msg'] = allData['stemmed'].apply(lambda x: lemmatizer(x))\n",
    "allData['Lemmas'] = allData['nonstop'].apply(lambda x: lemmatize_email(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests that one print makes sense: \n",
      " PLEASSSSSSSEEEEEE TEL ME V AVENT DONE SPORTSx\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tests that one print makes sense: \\n {allData['Message'][242]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Free', 'entry', '69', 'wkly', 'comp', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '69', 'Text', 'FA', '69', 'receive', 'entry', 'questionstd', 'txt', 'rateTCs', 'apply', '08452810075over18s']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>CompressedNums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, o...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "      <td>[Go, jurong, point, crazy, Available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[Free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[Free, entry, 69, wkly, comp, win, FA, Cup, fi...</td>\n",
       "      <td>[Free, entry, 69, wkly, comp, win, FA, Cup, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, t...</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "      <td>[U, dun, say, early, hor, U, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[Nah, I, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[Nah, I, dont, think, goes, usf, lives, around...</td>\n",
       "      <td>[nah, i, dont, think, goe, usf, live, around, ...</td>\n",
       "      <td>[Nah, I, dont, think, go, usf, life, around, t...</td>\n",
       "      <td>[Nah, I, dont, think, go, usf, life, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30407</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, posit, avail, late, octob, 1995, earli, feb...</td>\n",
       "      <td>[, position, available, late, october, 69, ear...</td>\n",
       "      <td>[, position, available, late, october, 69, ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34810</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Subject: 30</td>\n",
       "      <td>Subject 30</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[Subject, 30, ]</td>\n",
       "      <td>[subject, 30, ]</td>\n",
       "      <td>[Subject, 69, ]</td>\n",
       "      <td>[Subject, 69, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34840</th>\n",
       "      <td>0</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>its not the best but will get you started if ...</td>\n",
       "      <td>[, its, not, the, best, but, will, get, you, s...</td>\n",
       "      <td>[, best, get, started, dont, one, prices, quot...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quot, u...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quote, ...</td>\n",
       "      <td>[, best, get, start, dont, one, price, quote, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35892</th>\n",
       "      <td>0</td>\n",
       "      <td>cleanest list on the internet today ! only $ ...</td>\n",
       "      <td>cleanest list on the internet today  only  69...</td>\n",
       "      <td>[, cleanest, list, on, the, internet, today, o...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, cleanest, list, internet, today, 69, dollar...</td>\n",
       "      <td>[, clean, list, internet, today, 69, dollar, p...</td>\n",
       "      <td>[, clean, list, internet, today, 69, dollar, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40824</th>\n",
       "      <td>0</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>the position will be available from late octo...</td>\n",
       "      <td>[, the, position, will, be, available, from, l...</td>\n",
       "      <td>[, position, available, late, october, 1995, e...</td>\n",
       "      <td>[, posit, avail, late, octob, 1995, earli, feb...</td>\n",
       "      <td>[, position, available, late, october, 69, ear...</td>\n",
       "      <td>[, position, available, late, october, 69, ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18156 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "30407        0   the position will be available from late octo...   \n",
       "34810        0                                      \"Subject: 30    \n",
       "34840        0   its not the best but will get you started if ...   \n",
       "35892        0   cleanest list on the internet today ! only $ ...   \n",
       "40824        0   the position will be available from late octo...   \n",
       "\n",
       "                                                 no_punc  \\\n",
       "0      Go until jurong point crazy Available only in ...   \n",
       "1                                Ok lar Joking wif u oni   \n",
       "2      Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            U dun say so early hor U c already then say   \n",
       "4      Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                  ...   \n",
       "30407   the position will be available from late octo...   \n",
       "34810                                        Subject 30    \n",
       "34840   its not the best but will get you started if ...   \n",
       "35892   cleanest list on the internet today  only  69...   \n",
       "40824   the position will be available from late octo...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Go, until, jurong, point, crazy, Available, o...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3      [U, dun, say, so, early, hor, U, c, already, t...   \n",
       "4      [Nah, I, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                  ...   \n",
       "30407  [, the, position, will, be, available, from, l...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, its, not, the, best, but, will, get, you, s...   \n",
       "35892  [, cleanest, list, on, the, internet, today, o...   \n",
       "40824  [, the, position, will, be, available, from, l...   \n",
       "\n",
       "                                                 nonstop  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 2, wkly, comp, win, FA, Cup, fin...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, goes, usf, lives, around...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 1995, e...   \n",
       "34810                                    [Subject, 30, ]   \n",
       "34840  [, best, get, started, dont, one, prices, quot...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, position, available, late, october, 1995, e...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "0      [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                           [ok, lar, joke, wif, u, oni]   \n",
       "2      [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3          [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4      [nah, i, dont, think, goe, usf, live, around, ...   \n",
       "...                                                  ...   \n",
       "30407  [, posit, avail, late, octob, 1995, earli, feb...   \n",
       "34810                                    [subject, 30, ]   \n",
       "34840  [, best, get, start, dont, one, price, quot, u...   \n",
       "35892  [, cleanest, list, internet, today, 69, dollar...   \n",
       "40824  [, posit, avail, late, octob, 1995, earli, feb...   \n",
       "\n",
       "                                                  Lemmas  \\\n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...   \n",
       "1                         [Ok, lar, Joking, wif, u, oni]   \n",
       "2      [Free, entry, 69, wkly, comp, win, FA, Cup, fi...   \n",
       "3          [U, dun, say, early, hor, U, c, already, say]   \n",
       "4      [Nah, I, dont, think, go, usf, life, around, t...   \n",
       "...                                                  ...   \n",
       "30407  [, position, available, late, october, 69, ear...   \n",
       "34810                                    [Subject, 69, ]   \n",
       "34840  [, best, get, start, dont, one, price, quote, ...   \n",
       "35892  [, clean, list, internet, today, 69, dollar, p...   \n",
       "40824  [, position, available, late, october, 69, ear...   \n",
       "\n",
       "                                          CompressedNums  \n",
       "0      [Go, jurong, point, crazy, Available, bugis, n...  \n",
       "1                         [Ok, lar, Joking, wif, u, oni]  \n",
       "2      [Free, entry, 69, wkly, comp, win, FA, Cup, fi...  \n",
       "3          [U, dun, say, early, hor, U, c, already, say]  \n",
       "4      [Nah, I, dont, think, go, usf, life, around, t...  \n",
       "...                                                  ...  \n",
       "30407  [, position, available, late, october, 69, ear...  \n",
       "34810                                    [Subject, 69, ]  \n",
       "34840  [, best, get, start, dont, one, price, quote, ...  \n",
       "35892  [, clean, list, internet, today, 69, dollar, p...  \n",
       "40824  [, position, available, late, october, 69, ear...  \n",
       "\n",
       "[18156 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compressing Numbers\n",
    "print(compress_numbers(allData['Lemmas'][2]))\n",
    "allData['CompressedNums'] = allData['Lemmas'].apply(lambda x: compress_numbers(x))\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "659b2eb0-312f-4a0e-9b29-e61c48382e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Free', 'entry', '69', 'wkly', 'comp', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '69', 'Text', 'FA', '69', 'receive', 'entry', 'questionstd', 'txt', 'rateTCs', 'apply', '08452810075over18s']\n"
     ]
    }
   ],
   "source": [
    "cleanData = allData[['Category', 'CompressedNums']].copy()\n",
    "#cleanData['CompressedNums'][2]\n",
    "allData['Lemmas'][2]\n",
    "print(compress_numbers(allData['Lemmas'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298b1596-f2d1-4f86-bfab-179a3a03021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [jurong, bugis, Cine, Available, crazy, world,...\n",
       "1                           [wif, Joking, oni, lar, u, Ok]\n",
       "2        [Free, Cup, FA, 21st, apply, entry, 0845281007...\n",
       "3                    [already, hor, early, dun, U, say, c]\n",
       "4        [life, dont, though, go, usf, think, I, around...\n",
       "                               ...                        \n",
       "30407    [, prefer, position, february, available, appr...\n",
       "34810                                      [, Subject, 69]\n",
       "34840    [, price, quote, one, dont, fully, 69, get, po...\n",
       "35892    [, 69, per, internet, today, dollar, clean, list]\n",
       "40824    [, prefer, position, february, available, appr...\n",
       "Name: nondupe, Length: 18156, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate duplicates within the same email\n",
    "cleanData['nondupe'] = cleanData['CompressedNums'].apply(lambda x: list(set(x)))\n",
    "flat = cleanData['nondupe'].explode()\n",
    "\n",
    "# only want words that appear in multiple emails\n",
    "def find_multiple_appearances(strings):\n",
    "    string_count = {}\n",
    "    duplicates_set = set()\n",
    "\n",
    "    # Count occurrences of each string\n",
    "    for string in strings:\n",
    "        string_count[string] = string_count.get(string, 0) + 1\n",
    "\n",
    "    # Add strings with counts >= 2 to the duplicates set\n",
    "    for string, count in string_count.items():\n",
    "        if count >= 2:\n",
    "            duplicates_set.add(string)\n",
    "\n",
    "    return duplicates_set\n",
    "    \n",
    "allStrings = find_multiple_appearances(flat)\n",
    "len(allStrings)\n",
    "cleanData['nondupe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e09a120c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cleanData['CompressedNums'] = cleanData['CompressedNums'].apply(' '.join)\n",
    "\n",
    "# Initialize CountVectorizer with your specific vocabulary\n",
    "vectorizer = CountVectorizer(vocabulary=allStrings)\n",
    "\n",
    "# Fit and transform the 'cleaned_msg' column\n",
    "X = vectorizer.fit_transform(cleanData['CompressedNums'])\n",
    "\n",
    "# Convert the result to a DataFrame and add it to the original DataFrame\n",
    "count_df = pd.DataFrame.sparse.from_spmatrix(X, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the sparse DataFrame with the original DataFrame\n",
    "cleanData = cleanData.reset_index(drop=True)\n",
    "count_df = count_df.reset_index(drop=True)\n",
    "cleanData = pd.concat([cleanData, count_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb875374-61a4-490d-a451-0bc12a834b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18156, 50897) <class 'pandas.core.frame.DataFrame'>\n",
      "predicted size of the file: 629.0129642486572 Megabytes\n"
     ]
    }
   ],
   "source": [
    "#sum(cleanData.iloc[:, 3])\n",
    "print(cleanData.shape, type(cleanData))\n",
    "print(f\"predicted size of the file: {(18156 * (2 * 18156 - 1) + (6 * 50897)) / np.power(2, 20)} Megabytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c50b6864",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Sparse pandas data (column ) not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# None of this shit works - for now, we can just use a smaller dataset to test the rest of the code\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import dask.dataframe as dd \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# dask_df = dd.from_pandas(cleanData, npartitions=3)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# dask_df.to_parquet(\"data/cleanData.parquet\", compression=\"gzip\")\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mcleanData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleanData.parquet.gzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3101\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   3022\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3097\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   3098\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3099\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   3102\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3103\u001b[0m     path,\n\u001b[0;32m   3104\u001b[0m     engine,\n\u001b[0;32m   3105\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3106\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3107\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   3108\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3109\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3110\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m--> 480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    481\u001b[0m     df,\n\u001b[0;32m    482\u001b[0m     path_or_buf,\n\u001b[0;32m    483\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    484\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    485\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m    486\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    487\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parquet.py:190\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 190\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[0;32m    193\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\table.pxi:3874\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\pandas_compat.py:570\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataframe_to_arrays\u001b[39m(df, schema, preserve_index, nthreads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    563\u001b[0m                         safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    564\u001b[0m     (all_names,\n\u001b[0;32m    565\u001b[0m      column_names,\n\u001b[0;32m    566\u001b[0m      index_column_names,\n\u001b[0;32m    567\u001b[0m      index_descriptors,\n\u001b[0;32m    568\u001b[0m      index_columns,\n\u001b[0;32m    569\u001b[0m      columns_to_convert,\n\u001b[1;32m--> 570\u001b[0m      convert_fields) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_columns_to_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# NOTE(wesm): If nthreads=None, then we use a heuristic to decide whether\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# using a thread pool is worth it. Currently the heuristic is whether the\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# nrows > 100 * ncols and ncols > 1.\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nthreads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\pandas_compat.py:374\u001b[0m, in \u001b[0;36m_get_columns_to_convert\u001b[1;34m(df, schema, preserve_index, columns)\u001b[0m\n\u001b[0;32m    371\u001b[0m name \u001b[38;5;241m=\u001b[39m _column_name_to_strings(name)\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pandas_api\u001b[38;5;241m.\u001b[39mis_sparse(col):\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse pandas data (column \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m    377\u001b[0m columns_to_convert\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[0;32m    378\u001b[0m convert_fields\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Sparse pandas data (column ) not supported."
     ]
    }
   ],
   "source": [
    "# None of this shit works - for now, we can just use a smaller dataset to test the rest of the code\n",
    "\n",
    "# import dask.dataframe as dd \n",
    "# cleanData.to_csv('data/cleanData.csv', index=False) \n",
    "\n",
    "# # Pandas DataFrame to a Dask DataFrame\n",
    "# dask_df = dd.from_pandas(cleanData, npartitions=3)\n",
    "# dask_df.to_parquet(\"data/cleanData.parquet\", compression=\"gzip\")\n",
    "\n",
    "# current best option\n",
    "# dense_df = cleanData.to_dense()\n",
    "# dense_df.to_parquet('cleanData.parquet.gzip', compression='gzip')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
