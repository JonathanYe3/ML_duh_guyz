{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39GGICFzwDrj"
      },
      "source": [
        "# **Instructions**\n",
        "\n",
        "This document is a template, and you are not required to follow it exactly. However, the kinds of questions we ask here are the kinds of questions we want you to focus on. While you might have answered similar questions to these in your project presentations, we want you to go into a lot more detail in this write-up; you can refer to the Lab homeworks for ideas on how to present your data or results.\n",
        "\n",
        "You don't have to answer every question in this template, but you should answer roughly this many questions. Your answers to such questions should be paragraph-length, not just a bullet point. You likely still have questions of your own -- that's okay! We want you to convey what you've learned, how you've learned it, and demonstrate that the content from the course has influenced how you've thought about this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VDfC-ie19P"
      },
      "source": [
        "# Project Name\n",
        "Project mentor: the GOAT Edward Wang\n",
        "\n",
        "Nick Geissler <ngeissl2@jh.edu>, Annie Wang <awang105@jh.edu>, Jonathan Ye <jye41@jh.edu>, Evan Zhu <ezhu13@jh.edu>\n",
        "\n",
        "Link_to_git_repo - https://github.com/JonathanYe3/ML_duh_guyz.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqwI3PT-hBJo"
      },
      "source": [
        "# Outline and Deliverables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Af6y48e7HI"
      },
      "source": [
        "List the deliverables from your project proposal. For each uncompleted deliverable, please include a sentence or two on why you weren't able to complete it (e.g. \"decided to use an existing implementation instead\" or \"ran out of time\"). For each completed deliverable, indicate which section of this notebook covers what you did.\n",
        "\n",
        "If you spent substantial time on any aspects that weren't deliverables in your proposal, please list those under \"Additional Work\" and indicate where in the notebook you discuss them.\n",
        "\n",
        "### Uncompleted Deliverables\n",
        "1. \"Expect to complete #1: Spamicity evaluation\": This metric proved less important than others in our opinion (F1 score, overall accuracy, type 2 errors, etc.)\n",
        "2. \"Would like to complete #1: Further malevolent detection\": We believe this to be very intensive for marginal improvement. Our algorithm is quite accurate, and implementing some of these algorithms could've been an entire project in its own right.\n",
        "3. \"Would like to complete #2: Personalized deployment data\": Some group members were not comfortable disclosing the contents of their emails.\n",
        "4. \"Would like to complete #3: Error analysis\": With single words and tokens as features, and no current features in our preprocessing to capture clusters of words or even word orderings, this would be extremely difficult to do. It would addtitionally likely result in AdaBoost being incompatible with the newly preprocessed data.\n",
        "5. \"Would like to complete #4: Removal of typos\": We concluded this would in fact be disadvantageous. Many spam and scam emails utilize typos to seem more \"believable.\"\n",
        "\n",
        "\n",
        "### Completed Deliverables\n",
        "1. \"Must complete #1: Implement AdaBoost\": We discuss our dataset pre-processing [in \"Dataset\" below](#scrollTo=zFq-_D0khnhh&line=10&uniqifier=1).\n",
        "2. \"Must complete #2: Evaluation of performance\": We discuss training our logistic regression baseline [in \"Baselines\" below](#scrollTo=oMyqHUa0jUw7&line=5&uniqifier=1).\n",
        "3. \"Must complete #3: Basic success benchmark\": We discuss our model's basic performance [in \"Results\" below](#results).\n",
        "4. \"Expect to complete #2: Custom loss function\": We discuss our custom loss function that penalizes type 2 errors according to the user's specifications [in \"Custom loss function\" below](#custom-loss-function). \n",
        "5. \"Expect to complete #3: Visualization\": We visualize and interpret our results [in \"Results\" below](#results).\n",
        "6. \"Expect to complete #4: Comparative evaluation\": We compare our model's results against those of SVM and random forest [in \"Results\" below](#results).\n",
        "7. **\"Would like to complete #2: Personalized deployment data\": We sampled some proprietary emails to see if our model generalizes to real-world situtations in ##idk man maybe we scrape angie email that would be funny otherwise this thing would be uncompleted + The dataset covered all types of emails, from marketing to personal to corporate, and we are rly not that quirky its probably fine**\n",
        "\n",
        "### Additional Deliverables\n",
        "1. We ran an extensive grid search [EVAN PLEASE INDICATE THE SECTION HERE]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiq2aSauhSsS"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtWkhiIPfOfK"
      },
      "source": [
        "## What problem were you trying to solve or understand?\n",
        "\n",
        "Q. What are the real-world implications of this data and task?\n",
        "\n",
        "A. Email communication is one of the most important methods of information transmission in use today. Malevolent spam, phishing, and malware attacks threaten the safety and wellbeing of email users, resulting in monetary damages, security breaches, and privacy violations. Vulnerable populations such as the elderly or non-tech-savvy are particularly susceptible to such scams. Consequently, it is important to be able to accurately classify spam vs \"ham\" or non-spam email to alert and protect those who need it most. Also, when considering the real life implications of this task, we aim to specifically minimize type 2 errors (spam classified as ham) as it is far more likely for a type 2 error to lead to a scammed individual. We recognize that this results in some legitmate emails being sent to spam/scam, but conclude that this is worth the safety enhancement. Additionally, our implementation in fact introduces a hyperparameter which encodes this penalty, so the implementation in fact would potentially allow users to essentially vary the sensitivity of the algorithm to spam emails.\n",
        "\n",
        "How is this problem similar to others weâ€™ve seen in lectures, breakouts, and homeworks?\n",
        "\n",
        "A. Although there hasn't been a coding homework problem directly implementing AdaBoost, we've extensively covered error penalization and AdaBoost in lecture and for the midterm exam. We've also discussed/implemented classification problems like logistic regression, softmax regression, and SVM. During hyperparameter tuning, we also got to see examples of bias and variance tradeoff, as well as overfitting and underfitting, which has been extensively covered in lecture and homework 1.\n",
        "\n",
        "Q. What makes this problem unique?\n",
        "\n",
        "A. The scam industry is continually evolving and constantly deploys more advanced scams as technology evolves. Consequentially, to keep up, we need to continue development of novel approaches and review of old techniques at the same pace. Although spam detection is a fairly saturated subject, we wanted to develop an algorithm that prioritizes the real-life implication of type 2 errors. Additionally, AdaBoost doesn't seem to be a very common method currently in use for spam email detection. Perhaps additionally interesting, this problem could not be solved by just applying a pre-existing sklearn model, as there was no existing hyperparameter for a non-uniformly weighted loss function in the existing sklearn AdaBoost.\n",
        "\n",
        "Q. What ethical implications does this problem have?\n",
        "\n",
        "A. Scammers unethically trick people into giving away valuable things, whether that is information, money, both, or more. Also, cyber attacks that take advantage of vulnerable populations disproportionately harm those populations. We seek to help find an equitable solution. This problem also does tie somewhat into the ethics of user control. Since our implementation could allow a user to adjust the \"type 2 error\" penalty, they regain control over what information they see and what is filtered out, which is a particularly requested feature in technology these days."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFq-_D0khnhh"
      },
      "source": [
        "## Dataset(s)\n",
        "\n",
        "Q. Describe the dataset(s) you used.\n",
        "\n",
        "A. Our dataset combines three datasets found on Kaggle. Each datum included a categorized (spam or ham) email, which we were able to break down for further analysis. In total there were 11,976 ham emails and 6,180 spam emails.\n",
        "\n",
        "Q. How were they collected?\n",
        "\n",
        "A. We downloaded the raw data from Kaggle.\n",
        "\n",
        "Q. Why did you choose them?\n",
        "\n",
        "A.  These data sets were appealing because of their breadth and lent themselves well to our preprocessing framework. They were also free. The emails were clearly labeled and covered a wide range of topics.\n",
        "\n",
        "Q. How many examples in each?\n",
        "\n",
        "A. In total, we had 18,156 labeled emails and 56,214 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import guys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "# from AdaBoostClassifier import AdaBoostClassifier\n",
        "#%run AdaBoostWeak.py\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-processing\n",
        "\n",
        "Please see our preprocessing2 jupyter notebook: {insert link}. \n",
        "\n",
        "### Questions\n",
        "\n",
        "Q. What features did you use or choose not to use? Why?\n",
        "\n",
        "A. Each feature is a lemma of a word that was present in more than one email. A lemma of a word is specifically the root of a word present in an email (these lemmas were found by lemmatizing the words in the email using a pre-existing NLP model).\n",
        "\n",
        "Q. If you have categorical labels, were your datasets class-balanced?\n",
        "\n",
        "A. The dataset was entirely categorical, with labels for lemma features being either 0 if the lemma was contained in a given email and one otherwise. The overall label for each email was either a 1 for spam and a 0 for a legitimate email.\n",
        "\n",
        "Q. How did you deal with missing data? What about outliers?\n",
        "\n",
        "A. Missing data and outliers were not really an issue within our dataset. Each email had an associated label as spam or legitimate, with no missing labels. Additionally, it would be difficult and even perhaps erroneous to mark emails, which just consist entirely of sets of words for the purposes of our algorithm, as outliers by some strange metric.\n",
        "\n",
        "Q. What approach(es) did you use to pre-process your data? Why?\n",
        "\n",
        "A. We stripped the data of NaNs and punctuation, then broke the emails into arrays of tokenized words, and eliminated pre-classified \"stop words\" like conjunctions and other words that would not change the sentiment or perceived danger level of a sentence. After this, a lemmatizer from the NLTK package lemmatized the individual words. Then, some more particular things were done to enhance viability of the algorithm. Firstly, all numbers were compressed into one \"contains number\" feature. Additionally, lemmas were only kept if they appeared in more than one email. Despite this compression, we encountered computational issues owing to the volume of data. We used a sparse matrix to handle the transformation of preprocessed text to a numerical matrix which conserved more memory/storage and allowed for efficient training.\n",
        "\n",
        "Q. Are your features continuous or categorical? How do you treat these features differently?\n",
        "\n",
        "A. The features are entirely categorical. Because of this, we need not distinguish between categorical and continuous features or worry about how to handle the differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEuKEzM5ipag"
      },
      "outputs": [],
      "source": [
        "# For those same examples above, what do they look like after being pre-processed?\n",
        "# column names\n",
        "with open('data/column_names.txt', 'rb') as f:\n",
        "    column_names = [line.strip() for line in f] # feature labels\n",
        "\n",
        "sparse_dat = sparse.load_npz(\"data/sparse_df.npz\")\n",
        "\n",
        "# Extract labels from the first column\n",
        "labels = sparse_dat[:, 0] # ground truth labels - 0 ham, 1 spam\n",
        "\n",
        "# Create a list of column indices to keep\n",
        "to_keep = list(set(range(sparse_dat.shape[1])) - set([0]))\n",
        "\n",
        "# Extract the design matrix\n",
        "X = sparse_dat[:, to_keep]\n",
        "\n",
        "print(f'Example labels (indices of spam emails): \\n{labels[0:10]}\\nHere, we can see that the 3rd, 6th, 9th, and 10th emails are spam')\n",
        "\n",
        "# Get the indices of non-zero elements in the first row of the sparse matrix\n",
        "non_zero_indices = sparse_dat[2].nonzero()[1]\n",
        "\n",
        "# Get the corresponding column names\n",
        "tokens = [column_names[i] for i in non_zero_indices]\n",
        "\n",
        "print(f\"Example words (features) for the third email (spam email): \\n{tokens} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1cDLEwhAx0gP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([    2,     5,     8, ..., 15974, 15975, 15976], dtype=int32), array([0, 0, 0, ..., 0, 0, 0], dtype=int32)]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the distribution of your data before and after pre-processing.\n",
        "#   You may borrow from how we visualized data in the Lab homeworks.\n",
        "\n",
        "#Pie chart for spam and ham emails\n",
        "with open('data/alldatacounts.txt', 'rb') as f:\n",
        "    alldatacounts = [line.strip() for line in f]\n",
        "alldatacounts = np.array([int(alldatacounts[i]) for i in range(len(alldatacounts))])\n",
        "plt.pie(alldatacounts,labels = alldatacounts)\n",
        "plt.title(\"Proportion of emails that are Ham vs. Spam (Both Before and After Preprocessing)\")\n",
        "plt.legend([\"Ham\",\"Spam\"])\n",
        "\n",
        "# Concatenating all of the words from all spam emails into one string and same for ham\n",
        "non_zero_indices = [i for i in labels.nonzero()]\n",
        "print(non_zero_indices)\n",
        "#n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tASjmmtjiwvu"
      },
      "source": [
        "# Models and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlrwR9E1hnQ3"
      },
      "source": [
        "## Experimental Setup\n",
        "\n",
        "### Evaluation metrics\n",
        "\n",
        "Q. How did you evaluate your methods? Why is that a reasonable evaluation metric for the task?\n",
        "\n",
        "A. We analyzed multiple different metrics when determining how successful our algorithm was. Firstly, and perhaps most logically, we evaluated the overall accuracy of our AdaBoost algorithm. This is simply calculated as the ottal number of correct classifications relative to the entire dataset. This is the standard benchmark metric for classification algorithms. We also calculated the F1 score, but realize this is less important as the dataset is not class balanced. A final metric we used to evaluate our email classifier was the amount of \"type 1\" and \"type 2\" errors that the classifier makes. To clarify, a \"type 1\" error is when a legitimate email is classified as spam (as if our null hypothesis was that the email is legitimate) and a \"type 2\" error is when a spam email. Since we prioritize safety in our implementation, we value decreasing type 2 errors highly, even at the cost of some more type 1 errors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom loss function\n",
        "\n",
        "Q. What did you use for your loss function to train your models? Did you try multiple loss functions? Why or why not?\n",
        "\n",
        "A. Our custom loss function is pasted below. Rather than assign a uniform loss of 1 for any misclassification, we implemented the ability to adjust the type 2 errors (classifying ham when actually spam) by a multiplicative factor. So, for example, if our ith weak learner misclassified the jth email as ham when the true label was spam, the jth entry of the weak learner's error vector would receive an error value of pen_factor. For a large penalty (>1) this results in the alpha value being smaller if there were many type 2 errors. As a result, the weights for the particular sample will be higher! Hence, the algorithm will focus more attention on this misclassified emails and the type 2 errors. [adaboost for dummies](https://towardsdatascience.com/adaboost-for-dummies-breaking-down-the-math-and-its-equations-into-simple-terms-87f439757dcf)\n",
        "\n",
        "We did try a couple other loss functions, but they sucked. One of our preliminary ideas was to weight the alpha itself as a function of the proportion of type 2 errors, but we found this to be ineffective and less interpretable.\n",
        "\n",
        "Furthermore, we implemented our own Adaboost algorithm to leverage this custom loss function. [github](https://github.com/JonathanYe3/ML_duh_guyz/blob/main/AdaBoostWeakClassic.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUNxC358jPDr"
      },
      "outputs": [],
      "source": [
        "# Code for loss functions, evaluation metrics or link to Git repo\n",
        "\n",
        "def compute_error(y, y_pred, w_i, type2penalty, pen_factor):\n",
        "    '''\n",
        "    Calculate the error rate of a weak classifier m. Arguments:\n",
        "    y: actual target value\n",
        "    y_pred: predicted value by weak classifier\n",
        "    w_i: individual weights for each observation\n",
        "\n",
        "    \n",
        "    Note that all arrays should be the same length. Convert sparse array to regular array before calling\n",
        "    '''\n",
        "    if type2penalty:\n",
        "        error = (sum(w_i * (t2_pred_err_vec(y, y_pred, pen_factor)).astype(float)))/sum(w_i)\n",
        "    else:\n",
        "        error = (sum(w_i * (np.not_equal(y, y_pred)).astype(int)))/sum(w_i)\n",
        "\n",
        "    return error\n",
        "def t2_pred_err_vec(y,y_pred, pen_factor):\n",
        "    pred_err_vec = ((y_pred==-1) & (y==1))* pen_factor\n",
        "    better_err_vec = ((y_pred==1)) & (y==-1)\n",
        "    pred_err_vec = pred_err_vec+better_err_vec\n",
        "    if np.isnan(pred_err_vec).any(): print(\"WAHHHHH NAN\")\n",
        "    return pred_err_vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train/Test split\n",
        "\n",
        "Q. How did you split your data into train and test sets? Why?\n",
        "\n",
        "A. We stratified by the y labels - so that we had similar proportion of spam in both train + test. This is common practice and helps prevent the test set from being biased towards the majority class (ham) and ensures a fair evaluation of our model's ability to detect spam emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train test split\n",
        "\n",
        "# Use train_test_split.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, shuffle=True, stratify=labels.toarray().ravel())\n",
        "\n",
        "y_train_flat = y_train.copy().toarray().ravel()\n",
        "#y_train_flat[y_train_flat == -1] = 0 See if you have to run this line if anything sus\n",
        "\n",
        "y_test_flat = y_test.copy().toarray().ravel()\n",
        "# y_test_flat[y_test_flat == -1] = 0 Same here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMyqHUa0jUw7"
      },
      "source": [
        "## Baselines\n",
        "\n",
        "Q. What baselines did you compare against? Why are these reasonable?\n",
        "\n",
        "A. We compared our custom Adaboost model with scikit-learn's Support Vector Machine (SVM) and Random Forest classifiers, both with default parameters. These were reasonable choices for baselines because SVMs and Random Forests are popular and well-performing algorithms for text classification tasks like spam filtering. They achieve good accuracy and are relatively easy to implement, making them strong benchmarks. Additionally, unlike some complex models, SVMs and Random Forests offer some level of interpretability. This allows us to understand the factors influencing their spam/ham classifications, which can be valuable for improving our Adaboost model. Finally, By using default parameters, we establish a baseline performance without the influence of extensive tuning. This lets us compare our Adaboost's performance with these established algorithms to see if our custom loss function focusing on type 2 errors leads to any improvements.\n",
        "\n",
        "\n",
        "Q. Did you look at related work to contextualize how others methods or baselines have performed on this dataset/task? If so, how did those methods do?\n",
        "\n",
        "A. Yes, we looked at related work on spam classification to contextualize how other methods or baselines have performed on this task. In addition to SVMs and Random Forests, related work often explores other boosting algorithms like XGBoost or GBDT. Additionally, some studies investigate Naive Bayes classifiers, which are known for their simplicity and efficiency in text classification. Even simpler rule-based approaches based on keyword filtering might be examined as baselines. The performance of these related methods varies depending on the specific approach and dataset used. One goal was to compare their achieved accuracy with our Adaboost model and the chosen baselines (SVM and Random Forest). More importantly, however, we wanted to see if our type 2 penalty was effective, which is our novel contribution to the email classification problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to calculate error types\n",
        "\n",
        "def errors(y, y_pred):\n",
        "        \"\"\"\n",
        "        Calculate the proportion of type 2 errors - when the true label is 1 - spam, and the predicted label is 0 - ham\n",
        "\n",
        "        Args:\n",
        "        y: true labels\n",
        "        y_pred: predicted labels\n",
        "        \"\"\"\n",
        "        n = y.shape[0]\n",
        "        y[y == -1] = 0\n",
        "        type2errors = ((y == 1) & (y_pred == 0)).sum().item()\n",
        "        type1errors = ((y == 0) & (y_pred == 1)).sum().item()\n",
        "        correct = (y_pred == y).sum().item()\n",
        "        #print(np.unique(y_pred), np.unique(y))\n",
        "        return type2errors, type1errors, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVM\n",
        "\n",
        "from sklearn import svm\n",
        "svm_example = svm.SVC(probability = True)\n",
        "svm_example.fit(X_train, y_train_flat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train metrics\n",
        "predictions = svm_example.predict(X_train)\n",
        "type2, type1, correct = errors(y_train_flat, predictions)\n",
        "f1 = metrics.f1_score(y_true = y_train_flat, y_pred= predictions)\n",
        "\n",
        "svm_train_metrics = [\"svm\",type2, type1, correct/len(predictions), f1]\n",
        "\n",
        "# For ROC\n",
        "scores = svm_example.predict_proba(X_test)\n",
        "svm_fpr, svm_tpr, thresholds  = metrics.roc_curve(y_test_flat, scores[:,1])\n",
        "\n",
        "# type 2 error stuff TEST\n",
        "predictions = svm_example.predict(X_test)\n",
        "type2, type1, correct = errors(y_test_flat, predictions)\n",
        "f1 = metrics.f1_score(y_true = y_test_flat, y_pred= predictions)\n",
        "\n",
        "svm_test_metrics = [\"svm\", type2, type1, correct/len(predictions), f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train metrics\n",
        "predictions = rf.predict(X_train)\n",
        "type2, type1, correct = errors(y_train_flat, predictions)\n",
        "f1 = metrics.f1_score(y_true = y_train_flat, y_pred= predictions)\n",
        "\n",
        "rf_train_metrics = [\"rf\",type2, type1, correct/len(predictions), f1]\n",
        "\n",
        "# For ROC\n",
        "scores = rf.predict_proba(X_test)\n",
        "rf_fpr, rf_tpr, thresholds = metrics.roc_curve(y_test_flat, scores[:,1])\n",
        "\n",
        "# type 2 error stuff TEST\n",
        "predictions = rf.predict(X_test)\n",
        "type2, type1, correct = errors(y_test_flat, predictions)\n",
        "f1 = metrics.f1_score(y_true = y_test_flat, y_pred= predictions)\n",
        "\n",
        "rf_test_metrics = [\"rf\", type2, type1, correct/len(predictions), f1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqB48IF9kMBf"
      },
      "source": [
        "## Methods\n",
        "\n",
        "Q. What methods did you choose? Why did you choose them?\n",
        "\n",
        "A. As mentioned above, we chose to manually implement Adaboost so that we could leverage a custom loss function that penalized type 2 errors more heavily. Beyond this, we chose Adaboost in general due to its robustness against overfitting, relative interpretability, and the fact that most research into this task did not involve Adaboost. We chose to sklearn's decision trees as our weak learners, because adaboost typically boosts decision trees of limited depth.\n",
        "\n",
        "Q. How did you train these methods, and how did you evaluate them? Why?\n",
        "\n",
        "A. \n",
        "\n",
        "Q. Which methods were easy/difficult to implement and train? Why?\n",
        "\n",
        "A. Implementating Adaboost itself was decently hard. Big obstacle was getting the weak learners to be unique. Maybe also talk about boosting RF? [github](https://github.com/JonathanYe3/ML_duh_guyz/blob/main/AdaBoostWeakClassic.py)\n",
        "\n",
        "Our custom loss function was easy to implement, as we could simply adapt the current error calculation.\n",
        "\n",
        "\n",
        "Q. For each method, what hyperparameters did you evaluate? How sensitive was your model's performance to different hyperparameter settings?\n",
        "\n",
        "A. First, we ran a grid search to find the best set of parameters for our goal - to reduce type 2 error (actual spam email classified as ham) while not sacrificing too much accuracy. Details are in the grid search section, but we evaluated the rounds of boosting, max depth of our weak learners, and the penalty factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search\n",
        "\n",
        "EVAN WAHHHH - add details (explain validation set, cross fold, yada yada) and most importantly paste that figure in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do something here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the model\n",
        "\n",
        "Using our choise of parameters from grid search:\n",
        "\n",
        "penalty factor = 2\n",
        "\n",
        "decision tree depth = 5 - for the sake of speed\n",
        "\n",
        "number of boosting rounds = 200 - for the sake of speed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma4JoDzar6xU"
      },
      "outputs": [],
      "source": [
        "# Code for training models, or link to your Git repository\n",
        "%run AdaBoostWeakClassic.py\n",
        "\n",
        "aboost_final = AdaBoostWeakClassic(rounds = 200, type2penalty=True, pen_factor = 2.0, maxDTdepth=5)\n",
        "aboost_final.fit(X_train, y_train_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training metrics\n",
        "predictions = aboost_final.predict(X_train)\n",
        "type2, type1, correct = errors(y_train.toarray().ravel(), predictions)\n",
        "print(\"Final Model (without penalty) Training set Accuracy: \", correct/len(predictions))\n",
        "print(f'unique predictions - should be 0 and 1: {np.unique(predictions)}')\n",
        "print(f'type 2 errors: {type2} \\n type 1 errors: {type1}')\n",
        "# y_train_flat = y_train.copy().toarray().ravel()\n",
        "# y_train_flat[y_train_flat == -1] = 0\n",
        "\n",
        "f1 = metrics.f1_score(y_true = y_train_flat, y_pred= predictions)\n",
        "print(f'F1 score: {f1}')\n",
        "\n",
        "# aboost_train_metrics = [type2, type1, correct/len(predictions), f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aboost_train_metrics = [\"adaboost\",type2, type1, correct/len(predictions), f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Metrics\n",
        "# For ROC\n",
        "probits = aboost_final.predict_probs(X_test)\n",
        "ada_fin_fpr, ada_fin_tpr, thresholds  = metrics.roc_curve(y_test_flat, probits)\n",
        "\n",
        "predictions = aboost_final.predict(X_test)\n",
        "type2, type1, correct = errors(y_test_flat, predictions)\n",
        "f1 = metrics.f1_score(y_true = y_test_flat, y_pred= predictions)\n",
        "\n",
        "# aboost_test_metrics = [type2, type1, correct/len(predictions), f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aboost_test_metrics = [\"adaboost\",type2, type1, correct/len(predictions), f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO_kP1fmkWWk"
      },
      "outputs": [],
      "source": [
        "# Show plots of how these models performed during training. FUCK\n",
        "#  For example, plot train loss and train accuracy (or other evaluation metric) on the y-axis,\n",
        "#  with number of iterations or number of examples on the x-axis.\n",
        "plt.plot(range(2, 201, 10), aboost_final.accuracies)\n",
        "plt.xlabel(\"Boosting rounds\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Boosting rounds vs. Accuracy\")\n",
        "plt.show()\n",
        "plt.plot(range(2, 201, 10), aboost_final.type2errors)\n",
        "plt.xlabel(\"Boosting rounds\")\n",
        "plt.ylabel(\"Number of type 2 errors\")\n",
        "plt.title(\"Boosting rounds vs. Type 2 Errors\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zdp4_H-kx8H"
      },
      "source": [
        "## Results\n",
        "\n",
        "Show tables comparing your methods to the baselines.\n",
        "\n",
        "Q. What about these results surprised you? Why?\n",
        "\n",
        "A. \n",
        "\n",
        "Q. Did your models over- or under-fit? How can you tell? What did you do to address these issues?\n",
        "\n",
        "A. \n",
        "\n",
        "Q. What does the evaluation of your trained models tell you about your data? How do you expect these models might behave differently on different data?  \n",
        "\n",
        "A. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS2sjfbglG_V"
      },
      "outputs": [],
      "source": [
        "# Show plots or visualizations of your evaluation metric(s) on the train and test sets.\n",
        "#   What do these plots show about over- or under-fitting?\n",
        "#   You may borrow from how we visualized results in the Lab homeworks.\n",
        "#   Are there aspects of your results that are difficult to visualize? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC Curve Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(svm_fpr, svm_tpr, marker='.', label='Default SVM')\n",
        "plt.plot(rf_fpr, rf_tpr, marker='.', label='Default Random Forest')\n",
        "plt.plot(ada_fin_fpr, ada_fin_tpr, marker='.', label='Custom Adaboost')\n",
        "\n",
        "\n",
        "plt.title(\"ROC comparison\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "train_table = PrettyTable([\"train method\",\"type 2\", \"type 1\", \"accuracy\", \"F1\"])\n",
        "train_table.add_row(svm_train_metrics)\n",
        "train_table.add_row(rf_train_metrics)\n",
        "train_table.add_row(aboost_train_metrics)\n",
        "train_table._rows[-1] = [f\"\\033[1m{cell}\\033[0m\" for cell in train_table._rows[-1]]\n",
        "print(train_table)\n",
        "\n",
        "test_table = PrettyTable([\"test method\",\"type 2\", \"type 1\", \"accuracy\", \"F1\"])\n",
        "test_table.add_row(svm_test_metrics)\n",
        "test_table.add_row(rf_test_metrics)\n",
        "test_table.add_row(aboost_test_metrics)\n",
        "test_table._rows[-1] = [f\"\\033[1m{cell}\\033[0m\" for cell in test_table._rows[-1]]\n",
        "print(test_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2lOicoBYif7g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Category                                            Message\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n"
          ]
        }
      ],
      "source": [
        "# Load your data and print 2-3 examples\n",
        "df1 = pd.read_csv(\"data/spam.csv\", usecols=[0,1])\n",
        "print(df1.iloc[0:3,:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59EbS1GilSQ_"
      },
      "source": [
        "# Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugJXhZKNlUT4"
      },
      "source": [
        "## What you've learned\n",
        "\n",
        "*Note: you don't have to answer all of these, and you can answer other questions if you'd like. We just want you to demonstrate what you've learned from the project.*\n",
        "\n",
        "Q. What concepts from lecture/breakout were most relevant to your project? How so?\n",
        "\n",
        "A. The Adaboost lecture\n",
        "\n",
        "Q. What aspects of your project did you find most surprising?\n",
        "\n",
        "A. The fact that it outperforms sklearn default SVM, and is not horribly inefficient\n",
        "\n",
        "Q. What lessons did you take from this project that you want to remember for the next ML project you work on? Do you think those lessons would transfer to other datasets and/or models? Why or why not?\n",
        "\n",
        "A. \n",
        "\n",
        "Q. What was the most helpful feedback you received during your presentation? Why?\n",
        "\n",
        "A. We got no feedback\n",
        "\n",
        "Q. If you had two more weeks to work on this project, what would you do next? Why?\n",
        "\n",
        "A. Probably nothing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
